{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maedr3\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape, Dropout, BatchNormalization, Embedding, Flatten, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../chapter 8/data/movie_reviews.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SentimentText = data.SentimentText.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \n",
    "    string = re.sub(r\"https?\\://\\S+\", '', string)\n",
    "    string = re.sub(r'\\<a href', ' ', string)\n",
    "    string = re.sub(r'&amp;', '', string) \n",
    "    string = re.sub(r'<br />', ' ', string)\n",
    "    string = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', string)\n",
    "    string = re.sub('\\d','', string)\n",
    "    string = re.sub(r\"can\\'t\", \"cannot\", string)\n",
    "    string = re.sub(r\"it\\'s\", \"it is\", string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SentimentText = data.SentimentText.apply(lambda x: clean_str(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie    43558\n",
       "film     39095\n",
       "it       30659\n",
       "one      26509\n",
       "is       20355\n",
       "like     20270\n",
       "good     15099\n",
       "the      13913\n",
       "time     12682\n",
       "even     12656\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(data['SentimentText']).split()).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') + ['movie', 'film', 'time']\n",
    "stop_words = set(stop_words)\n",
    "remove_stop_words = lambda r: [[word for word in word_tokenize(sente) if word not in stop_words] for sente in sent_tokenize(r)]\n",
    "data['SentimentText'] = data['SentimentText'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(text):    \n",
    "    try:\n",
    "        return ' '.join(text[0])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SentimentText = data.SentimentText.apply(lambda x: combine_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77348 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(list(data['SentimentText']))\n",
    "sequences = tokenizer.texts_to_sequences(data['SentimentText'])\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(filename, word_index , num_words, embedding_dim):\n",
    "    embeddings_index = {}\n",
    "    file = open(filename, encoding=\"utf-8\")\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coef = np.asarray(values[1:])\n",
    "        embeddings_index[word] = coef\n",
    "    file.close()\n",
    "    \n",
    "    embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "    for word, pos in word_index.items():\n",
    "        if pos >= num_words:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[pos] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = load_embedding('movie_embedding.txt', word_index, len(word_index), EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews, pd.get_dummies(data.Sentiment), test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((MAX_SEQUENCE_LENGTH,))\n",
    "embedding_layer = Embedding(len(word_index),\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                    trainable=False)(inp)\n",
    "model = Dropout(0.10)(embedding_layer)\n",
    "model = BatchNormalization()(model)\n",
    "model = LSTM(256, dropout=0.1, return_sequences=True)(model)\n",
    "model = LSTM(256, dropout=0.1)(model)\n",
    "model = Dense(units=128, activation='relu')(model)\n",
    "model = Dense(units=32, activation='relu')(model)\n",
    "model = Dropout(0.3)(model)\n",
    "predictions = Dense(units=2, activation='softmax')(model)\n",
    "model = Model(inputs = inp, outputs = predictions)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 100, 16)           1237568   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 100, 16)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100, 16)           64        \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100, 256)          279552    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,079,586\n",
      "Trainable params: 841,986\n",
      "Non-trainable params: 1,237,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 343s 17ms/step - loss: 0.6901 - acc: 0.5492 - val_loss: 0.6836 - val_acc: 0.6530\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 665s 33ms/step - loss: 0.6768 - acc: 0.6477 - val_loss: 0.6651 - val_acc: 0.6950\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 684s 34ms/step - loss: 0.6564 - acc: 0.6828 - val_loss: 0.6384 - val_acc: 0.7106\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 685s 34ms/step - loss: 0.6281 - acc: 0.7014 - val_loss: 0.6054 - val_acc: 0.7178\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 435s 22ms/step - loss: 0.5966 - acc: 0.7039 - val_loss: 0.5702 - val_acc: 0.7268\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 377s 19ms/step - loss: 0.5704 - acc: 0.7164 - val_loss: 0.5429 - val_acc: 0.7380\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 427s 21ms/step - loss: 0.5537 - acc: 0.7248 - val_loss: 0.5239 - val_acc: 0.7442\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 345s 17ms/step - loss: 0.5399 - acc: 0.7354 - val_loss: 0.5113 - val_acc: 0.7496\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 623s 31ms/step - loss: 0.5322 - acc: 0.7414 - val_loss: 0.5003 - val_acc: 0.7606\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 566s 28ms/step - loss: 0.5197 - acc: 0.7490 - val_loss: 0.4881 - val_acc: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f3cbedd470>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(preds, 1), np.argmax(y_test.values, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922</td>\n",
       "      <td>531</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>623</td>\n",
       "      <td>1924</td>\n",
       "      <td>2547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2545</td>\n",
       "      <td>2455</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "Actual                     \n",
       "0          1922   531  2453\n",
       "1           623  1924  2547\n",
       "All        2545  2455  5000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(np.argmax(y_test.values, axis=1), name='Actual')\n",
    "y_pred = pd.Series(np.argmax(preds, axis=1), name='Predicted')\n",
    "pd.crosstab(y_actual, y_pred, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "warning spoilers really stupid group young italy find warrior souls one wears becomes possessed spirit demon killing several friends die blade demon corpse waste viewers fine young ladies leave clothes gore ludicrous best acting terrible perfect bad script\n",
      "\n",
      "Predicted sentiment = Negative\n",
      "\n",
      "Actual sentiment = Negative\n"
     ]
    }
   ],
   "source": [
    "review_num = 110\n",
    "print(\"Review: \\n\"+tokenizer.sequences_to_texts([X_test[review_num]])[0])\n",
    "sentiment = \"Positive\" if np.argmax(preds[review_num]) else \"Negative\"\n",
    "print(\"\\nPredicted sentiment = \"+ sentiment)\n",
    "sentiment = \"Positive\" if np.argmax(y_test.values[review_num]) else \"Negative\"\n",
    "print(\"\\nActual sentiment = \"+ sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
